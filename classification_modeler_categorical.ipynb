{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0902a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f4f4ac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "import joblib\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "27908653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_show_model_report(model,x,y,model_name):\n",
    "    print(f\"[++] PRINTING MODEL REPORT FOR MODEL : {model_name}\")\n",
    "    train_x,val_x,train_y,val_y = train_test_split(x,y,test_size=0.1)\n",
    "    model.fit(train_x,train_y)\n",
    "    pred_y = model.predict(val_x)\n",
    "    acc_score = accuracy_score(val_y,pred_y)\n",
    "    print(f\"[++] PRINTING ACCURACY SCORES ....\")\n",
    "    print(f\" accuracy_score:{acc_score}\")\n",
    "    print(f\"[++] SAVING THE MODEL \")\n",
    "    return acc_score\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f228aa2f",
   "metadata": {},
   "source": [
    "# UNCOMMENT THE MODEL YOU WANT TO RUN IN BELOW FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "213061ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "#     rf_clf = RandomForestClassifier(n_estimators=trial.suggest_categorical('rf_est',[100,200,300]),\n",
    "#                                     criterion=trial.suggest_categorical('rf_crt',[\"gini\",\"entropy\"]),verbose=1)\n",
    "#     score = save_show_model_report(rf_clf,x,y,\"Random_Forest\") \n",
    "#     et_clf = ExtraTreesClassifier(n_estimators=trial.suggest_categorical('et_est',[100,200,300]),\n",
    "#                                   class_weight=trial.suggest_categorical('et_cl_wt',[\"balanced\", \"balanced_subsample\"]),verbose=1)\n",
    "#     score = save_show_model_report(et_clf,x,y,\"Extra_Trees\")  \n",
    "#     lr_clf = LogisticRegression(penalty=\"none\",\n",
    "#                                 C=trial.suggest_categorical('lr_C',[1.0,0.1]),\n",
    "#                                 solver=trial.suggest_categorical('lr_solver',[\"newton-cg\", \"sag\", \"saga\"])\n",
    "#                                 ,verbose=1)\n",
    "#     score = save_show_model_report(lr_clf,x,y,\"Logistic_Regression\") \n",
    "#     Kn_clf = KNeighborsClassifier(n_neighbors=trial.suggest_categorical(\"k_nei\",[3,4,5]),\n",
    "#                                   weights=trial.suggest_categorical(\"k_wei\",[\"uniform\",\"distance\"]),\n",
    "#                                   algorithm=trial.suggest_categorical(\"K_algo\",[\"auto\",\"ball_tree\",\"kd_tree\",\"brute\"]),\n",
    "#                                  p=trial.suggest_categorical(\"K_p\",[1,2]))\n",
    "#     score = save_show_model_report(Kn_clf,x,y,\"K_Neighbors\")\n",
    "#     SVC_clf = SVC(kernel=trial.suggest_categorical(\"SVC_ker\",[\"linear\",\"poly\",\"rbf\",\"sigmoid\"]),\n",
    "#                  gamma = trial.suggest_categorical(\"SVC_gamma\",[\"scale\",\"auto\"]),\n",
    "#                  verbose=1)\n",
    "#     score = save_show_model_report(SVC_clf,x,y,\"SVC\")\n",
    "#     DT_clf = DecisionTreeClassifier(criterion=trial.suggest_categorical(\"DT_cri\",[\"gini\",\"entropy\"]),\n",
    "#                                    splitter=trial.suggest_categorical(\"DT_spl\",[\"best\",\"random\"]))\n",
    "#     score = save_show_model_report(DT_clf,x,y,\"Decision_Tree\")\n",
    "    XGB_clf = XGBClassifier(n_estimators=trial.suggest_categorical(\"XGB_est\",[100,200,300]),\n",
    "                           learning_rate = trial.suggest_categorical(\"XGB_lr\",[0.1,0.01,0.001]),\n",
    "                           booster= trial.suggest_categorical(\"XGB_boost\",[\"gbtree\",\"gblinear\",\"dart\"]),\n",
    "                           tree_method = trial.suggest_categorical(\"XGB_tree\",[\"exact\",\"approx\",\"hist\",\"gpu_hist\"]),\n",
    "                           predictor=\"cpu_predictor\")\n",
    "    score = save_show_model_report(XGB_clf,x,y,\"XGB_Classifier\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2c8b0086",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_csv(\"./main_datasets/completely_scaled_data.csv\")\n",
    "y = main_df[\"target\"]\n",
    "main_df.drop(\"target\",axis=1,inplace=True)\n",
    "x = main_df\n",
    "cat_cols = ['Device_size_type',\n",
    "       'Transparent_conductive_oxide_type', 'Electron_transport_layer_type',\n",
    "       'Sweep_direction', 'Perovksite_depostion_method',\n",
    "       'Hole_transport_layer_type', 'Conductive_electrode_layer',\n",
    "       'Device_structure']\n",
    "x = x[cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "98028555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-08 12:15:40,418]\u001b[0m A new study created in memory with name: no-name-e61f6058-1ab8-46e6-954e-4756c00428c6\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-08 12:15:42,184]\u001b[0m Trial 0 finished with value: 0.8571428571428571 and parameters: {'XGB_est': 200, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 0 with value: 0.8571428571428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.8571428571428571\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:42,519]\u001b[0m Trial 1 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 300, 'XGB_lr': 0.001, 'XGB_boost': 'gbtree', 'XGB_tree': 'hist'}. Best is trial 0 with value: 0.8571428571428571.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:42,569]\u001b[0m Trial 2 finished with value: 1.0 and parameters: {'XGB_est': 300, 'XGB_lr': 0.001, 'XGB_boost': 'gblinear', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:1.0\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:44,942]\u001b[0m Trial 3 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 300, 'XGB_lr': 0.01, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:46,702]\u001b[0m Trial 4 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 200, 'XGB_lr': 0.001, 'XGB_boost': 'dart', 'XGB_tree': 'approx'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:46,734]\u001b[0m Trial 5 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 100, 'XGB_lr': 0.1, 'XGB_boost': 'gblinear', 'XGB_tree': 'approx'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:46,784]\u001b[0m Trial 6 finished with value: 0.14285714285714285 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gblinear', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:15:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:15:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.14285714285714285\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:47,121]\u001b[0m Trial 7 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 300, 'XGB_lr': 0.01, 'XGB_boost': 'gbtree', 'XGB_tree': 'exact'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:47,155]\u001b[0m Trial 8 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'gblinear', 'XGB_tree': 'exact'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:15:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:47,496]\u001b[0m Trial 9 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 300, 'XGB_lr': 0.001, 'XGB_boost': 'gbtree', 'XGB_tree': 'approx'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:49,271]\u001b[0m Trial 10 finished with value: 0.2857142857142857 and parameters: {'XGB_est': 200, 'XGB_lr': 0.001, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:49,316]\u001b[0m Trial 11 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 200, 'XGB_lr': 0.1, 'XGB_boost': 'gblinear', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:49,363]\u001b[0m Trial 12 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 200, 'XGB_lr': 0.1, 'XGB_boost': 'gblinear', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.2857142857142857\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:15:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:15:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:50,523]\u001b[0m Trial 13 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 200, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:50,957]\u001b[0m Trial 14 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 100, 'XGB_lr': 0.001, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:51,014]\u001b[0m Trial 15 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gblinear', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:15:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:51,282]\u001b[0m Trial 16 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 200, 'XGB_lr': 0.001, 'XGB_boost': 'gbtree', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:51,494]\u001b[0m Trial 17 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 200, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'exact'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:51,551]\u001b[0m Trial 18 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 300, 'XGB_lr': 0.001, 'XGB_boost': 'gblinear', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:15:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:52,107]\u001b[0m Trial 19 finished with value: 0.8571428571428571 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:52,177]\u001b[0m Trial 20 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 300, 'XGB_lr': 0.001, 'XGB_boost': 'gblinear', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.8571428571428571\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:15:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:52,610]\u001b[0m Trial 21 finished with value: 0.8571428571428571 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.8571428571428571\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:53,085]\u001b[0m Trial 22 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:53,525]\u001b[0m Trial 23 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:53,971]\u001b[0m Trial 24 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:54,398]\u001b[0m Trial 25 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ...."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:54,592]\u001b[0m Trial 26 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 200, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'exact'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:54,932]\u001b[0m Trial 27 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'approx'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:54,980]\u001b[0m Trial 28 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 200, 'XGB_lr': 0.001, 'XGB_boost': 'gblinear', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:15:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:55,431]\u001b[0m Trial 29 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:57,427]\u001b[0m Trial 30 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 300, 'XGB_lr': 0.001, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:57,939]\u001b[0m Trial 31 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:58,427]\u001b[0m Trial 32 finished with value: 0.8571428571428571 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.8571428571428571\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:58,982]\u001b[0m Trial 33 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:59,475]\u001b[0m Trial 34 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:15:59,951]\u001b[0m Trial 35 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'approx'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:15:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:00,329]\u001b[0m Trial 36 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 300, 'XGB_lr': 0.01, 'XGB_boost': 'gbtree', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:00,368]\u001b[0m Trial 37 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 100, 'XGB_lr': 0.1, 'XGB_boost': 'gblinear', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:16:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:03,938]\u001b[0m Trial 38 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 300, 'XGB_lr': 0.001, 'XGB_boost': 'dart', 'XGB_tree': 'exact'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:03,987]\u001b[0m Trial 39 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 200, 'XGB_lr': 0.01, 'XGB_boost': 'gblinear', 'XGB_tree': 'approx'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:16:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:04,152]\u001b[0m Trial 40 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 100, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-08 12:16:04,703]\u001b[0m Trial 41 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:05,202]\u001b[0m Trial 42 finished with value: 0.14285714285714285 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.14285714285714285\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:05,762]\u001b[0m Trial 43 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:06,299]\u001b[0m Trial 44 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:07,735]\u001b[0m Trial 45 finished with value: 0.2857142857142857 and parameters: {'XGB_est': 200, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:07,793]\u001b[0m Trial 46 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 300, 'XGB_lr': 0.001, 'XGB_boost': 'gblinear', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.2857142857142857\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:16:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:08,301]\u001b[0m Trial 47 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 100, 'XGB_lr': 0.1, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:08,537]\u001b[0m Trial 48 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 200, 'XGB_lr': 0.01, 'XGB_boost': 'gbtree', 'XGB_tree': 'exact'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:08,595]\u001b[0m Trial 49 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 300, 'XGB_lr': 0.001, 'XGB_boost': 'gblinear', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:16:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:09,089]\u001b[0m Trial 50 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 100, 'XGB_lr': 0.1, 'XGB_boost': 'dart', 'XGB_tree': 'approx'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:09,128]\u001b[0m Trial 51 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 100, 'XGB_lr': 0.1, 'XGB_boost': 'gblinear', 'XGB_tree': 'approx'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:16:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:09,427]\u001b[0m Trial 52 finished with value: 0.2857142857142857 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'approx'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:09,462]\u001b[0m Trial 53 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 100, 'XGB_lr': 0.1, 'XGB_boost': 'gblinear', 'XGB_tree': 'approx'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:09,498]\u001b[0m Trial 54 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 100, 'XGB_lr': 0.1, 'XGB_boost': 'gblinear', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.2857142857142857\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:16:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:16:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:09,954]\u001b[0m Trial 55 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:11,380]\u001b[0m Trial 56 finished with value: 0.2857142857142857 and parameters: {'XGB_est': 200, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.2857142857142857\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:11,857]\u001b[0m Trial 57 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:13,286]\u001b[0m Trial 58 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 200, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:13,322]\u001b[0m Trial 59 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 100, 'XGB_lr': 0.1, 'XGB_boost': 'gblinear', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:13,360]\u001b[0m Trial 60 finished with value: 0.8571428571428571 and parameters: {'XGB_est': 100, 'XGB_lr': 0.001, 'XGB_boost': 'gblinear', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:13,398]\u001b[0m Trial 61 finished with value: 0.2857142857142857 and parameters: {'XGB_est': 100, 'XGB_lr': 0.001, 'XGB_boost': 'gblinear', 'XGB_tree': 'approx'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:16:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:16:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.8571428571428571\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:16:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.2857142857142857\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:14,777]\u001b[0m Trial 62 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 200, 'XGB_lr': 0.001, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:16,135]\u001b[0m Trial 63 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 200, 'XGB_lr': 0.001, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:16,368]\u001b[0m Trial 64 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 200, 'XGB_lr': 0.001, 'XGB_boost': 'gbtree', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:16,406]\u001b[0m Trial 65 finished with value: 0.2857142857142857 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'gblinear', 'XGB_tree': 'approx'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:16:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.2857142857142857\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:16,803]\u001b[0m Trial 66 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 100, 'XGB_lr': 0.001, 'XGB_boost': 'dart', 'XGB_tree': 'exact'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:18,317]\u001b[0m Trial 67 finished with value: 0.8571428571428571 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.8571428571428571\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:20,223]\u001b[0m Trial 68 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 300, 'XGB_lr': 0.001, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:21,770]\u001b[0m Trial 69 finished with value: 0.8571428571428571 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.8571428571428571\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:23,875]\u001b[0m Trial 70 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 300, 'XGB_lr': 0.001, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:25,538]\u001b[0m Trial 71 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:27,087]\u001b[0m Trial 72 finished with value: 1.0 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:1.0\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:28,568]\u001b[0m Trial 73 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:30,141]\u001b[0m Trial 74 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:31,642]\u001b[0m Trial 75 finished with value: 0.8571428571428571 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.8571428571428571\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:33,224]\u001b[0m Trial 76 finished with value: 0.8571428571428571 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.8571428571428571\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:34,628]\u001b[0m Trial 77 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:36,167]\u001b[0m Trial 78 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:37,787]\u001b[0m Trial 79 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:39,263]\u001b[0m Trial 80 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:39,561]\u001b[0m Trial 81 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:41,127]\u001b[0m Trial 82 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:42,644]\u001b[0m Trial 83 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:44,156]\u001b[0m Trial 84 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:45,769]\u001b[0m Trial 85 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:47,197]\u001b[0m Trial 86 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:47,236]\u001b[0m Trial 87 finished with value: 0.8571428571428571 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'gblinear', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:16:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.8571428571428571\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:48,646]\u001b[0m Trial 88 finished with value: 0.2857142857142857 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.2857142857142857\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:48,946]\u001b[0m Trial 89 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 300, 'XGB_lr': 0.01, 'XGB_boost': 'gbtree', 'XGB_tree': 'exact'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:48,983]\u001b[0m Trial 90 finished with value: 0.14285714285714285 and parameters: {'XGB_est': 100, 'XGB_lr': 0.001, 'XGB_boost': 'gblinear', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:49,039]\u001b[0m Trial 91 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 300, 'XGB_lr': 0.01, 'XGB_boost': 'gblinear', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:49,076]\u001b[0m Trial 92 finished with value: 0.42857142857142855 and parameters: {'XGB_est': 100, 'XGB_lr': 0.1, 'XGB_boost': 'gblinear', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:16:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.14285714285714285\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:16:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:16:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.42857142857142855\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:16:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ...."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:49,129]\u001b[0m Trial 93 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 300, 'XGB_lr': 0.001, 'XGB_boost': 'gblinear', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-08 12:16:50,586]\u001b[0m Trial 94 finished with value: 0.14285714285714285 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:50,624]\u001b[0m Trial 95 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'gblinear', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.14285714285714285\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:16:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:52,170]\u001b[0m Trial 96 finished with value: 0.7142857142857143 and parameters: {'XGB_est': 300, 'XGB_lr': 0.1, 'XGB_boost': 'gbtree', 'XGB_tree': 'gpu_hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:52,205]\u001b[0m Trial 97 finished with value: 0.14285714285714285 and parameters: {'XGB_est': 100, 'XGB_lr': 0.01, 'XGB_boost': 'gblinear', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.7142857142857143\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:16:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.14285714285714285\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:53,593]\u001b[0m Trial 98 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 200, 'XGB_lr': 0.01, 'XGB_boost': 'dart', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-12-08 12:16:53,630]\u001b[0m Trial 99 finished with value: 0.5714285714285714 and parameters: {'XGB_est': 100, 'XGB_lr': 0.001, 'XGB_boost': 'gblinear', 'XGB_tree': 'hist'}. Best is trial 2 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING MODEL REPORT FOR MODEL : XGB_Classifier\n",
      "[12:16:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:16:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[++] PRINTING ACCURACY SCORES ....\n",
      " accuracy_score:0.5714285714285714\n",
      "[++] SAVING THE MODEL \n",
      "[++] PRINTING BEST PARAMETERS\n",
      "{'XGB_est': 300, 'XGB_lr': 0.001, 'XGB_boost': 'gblinear', 'XGB_tree': 'hist'}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective,n_trials=100)\n",
    "print(\"[++] PRINTING BEST PARAMETERS\")\n",
    "best_p = study.best_params\n",
    "print(best_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a10991",
   "metadata": {},
   "source": [
    "# MENTION MODEL NAME BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0d5ed15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = \"XGBClassifier\" #EDIT MODEL NAME HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "daf1daf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "SCORE :: 0.5714285714285714\n",
      "[++] FOLD 0 model is deposited\n",
      "[12:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "SCORE :: 0.2857142857142857\n",
      "[++] FOLD 1 model is deposited\n",
      "[12:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "SCORE :: 0.5714285714285714\n",
      "[++] FOLD 2 model is deposited\n",
      "[12:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "SCORE :: 0.7142857142857143\n",
      "[++] FOLD 3 model is deposited\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "SCORE :: 0.7142857142857143\n",
      "[++] FOLD 4 model is deposited\n",
      "[12:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "SCORE :: 0.7142857142857143\n",
      "[++] FOLD 5 model is deposited\n",
      "[12:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "SCORE :: 0.42857142857142855\n",
      "[++] FOLD 6 model is deposited\n",
      "[12:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "SCORE :: 0.42857142857142855\n",
      "[++] FOLD 7 model is deposited\n",
      "[12:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "SCORE :: 0.5\n",
      "[++] FOLD 8 model is deposited\n",
      "[12:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"predictor\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "SCORE :: 0.5\n",
      "[++] FOLD 9 model is deposited\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\users\\001001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10,shuffle=True,random_state=123)\n",
    "acc_list = []\n",
    "for num,(train_idx,test_idx) in enumerate(skf.split(x,y)):\n",
    "    main_clf_model= XGBClassifier(n_estimators=300,\n",
    "                           learning_rate =0.001,\n",
    "                           booster= \"gblinear\",\n",
    "                           tree_method =\"hist\",\n",
    "                           predictor=\"cpu_predictor\")  #CHANGE HERE THE CLASSIFIER MODEL ACC TO OBJECTIVE FUNCTION \n",
    "    x_train,x_test = x.loc[train_idx],x.loc[test_idx]\n",
    "    y_train,y_test = y.loc[train_idx],y.loc[test_idx]\n",
    "    main_clf_model.fit(x_train,y_train)\n",
    "    score = main_clf_model.score(x_test,y_test)\n",
    "    acc_list.append(score)\n",
    "    print(f\"SCORE :: {score}\")\n",
    "    try:\n",
    "        joblib.dump(main_clf_model,f\"./cat_models/{modelName}_folded_models/{modelName}_fold{num}_tuned.pkl\")\n",
    "        print(f\"[++] FOLD {num} model is deposited\")\n",
    "    except:\n",
    "        os.mkdir(f\"./cat_models/{modelName}_folded_models\")\n",
    "        print(f\"[++] FILE SYSTEM CREATED \")\n",
    "        joblib.dump(main_clf_model,f\"./cat_models/{modelName}_folded_models/{modelName}_fold{num}_tuned.pkl\")\n",
    "        print(f\"[++] FOLD {num} model is deposited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c1355a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "494729cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(li):\n",
    "    tot = 0\n",
    "    for i in li:\n",
    "        tot+=i\n",
    "    m = tot/len(li)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "25364557",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log = f'LOG FOR :{(modelName)} \\n'\n",
    "log += \"BEST PARAMETERS :: \"\n",
    "log += str(best_p)\n",
    "log += \"\\n\"\n",
    "log += \"\\n MODEL RESULTS\\n\"\n",
    "log += f\"AVERAGE ACCURACY : {mean(acc_list)}\\n\"\n",
    "log += f\"MAX ACCURACY : {max(acc_list)}\\n\"\n",
    "log += f\"MIN ACCURACY : {min(acc_list)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f175011b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG FOR :XGBClassifier \n",
      "BEST PARAMETERS :: {'XGB_est': 300, 'XGB_lr': 0.001, 'XGB_boost': 'gblinear', 'XGB_tree': 'hist'}\n",
      "\n",
      " MODEL RESULTS\n",
      "AVERAGE ACCURACY : 0.5428571428571429\n",
      "MAX ACCURACY : 0.7142857142857143\n",
      "MIN ACCURACY : 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d64541f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./cat_models/{modelName}_folded_models/{modelName}_log.txt\",\"w+\") as file:\n",
    "    file.write(log)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54be93da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
